{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Dataverse Curation Guide Introduction Data curation \u2013 the active management of research data as it is created, maintained, used, archived, shared, and reused \u2013 is a core component within the assemblage of infrastructure, processes, schemas, and curator expertise that supports best practices in Research Data Management (RDM). The execution of a well-articulated data curation workflow can make good data better by expertly describing its contents, creating a coherent structure, providing meaningful documentation, enabling automation through code and syntax, and linking to other data and outputs. This guide provides step-by-step instructions for curating new datasets deposited in Dataverse. The guide is framed around the acronym CURATION to provide an easy reminder for curators, especially those starting out, of the main steps in the curation process. This framework is adapted from the Data Curation Network\u2019s CURATED steps ( Johnston et al. 2018 ) for use in a bilingual context and is intended to outline and provide guidance on curation best practices in Dataverse. Data curation is not always a linear process; the type of data you are working with, your institutional policies or practices, your comfort level with curation, and the amount of time the researcher is able to dedicate to the process may require you to skip steps or complete the steps in a different order. You may also need to circle back and complete some of the steps a second time. The level of curation your institution is able to offer, given competing priorities and number of staff dedicated to the curation service, may also determine how many curation steps you can complete. Our Guide acknowledges there is no \u201cone size fits all\u201d model to data curation. The level and quality of curation is dependent on local resourcing, capacity, policies, priorities, and institutional strategic direction. As a result, the Guide has been developed with flexibility in mind. It can be used by new or experienced curators within academic institutions of all sizes, and it can be adapted by institutions to meet the needs of local policies and procedures. Possible Curation Service Scenarios Service Type Description Unmediated Curation There is no intervention from the RDM service. The researcher creates their own dataverse and dataset, submits their data and publishes it. Semi-mediated curation The RDM service creates a dataverse or starts a dataset deposit and assigns a role to the researcher. The researcher submits data to their dataverse (or dataset). Depending on local policy, the dataset is either flagged for review by the institutional dataverse administrators, or the depositor requests to have the dataset reviewed by the data management team before or after it is published. Mediated curation Data is submitted by the researcher to the RDM service. The RDM service creates the dataverse (or dataset) and the data is curated by the library and published once approved by the researcher. Levels of Curation The CURATION checklist is divided into 3 levels: Level 1, Level 2 and Level 3. Level 1 is the basic required information that should be completed to publish a dataset in Dataverse. Depending on the level of service that your institution is able to provide, you may be able to complete some of the items in levels 2 and 3. A description of each level is below. For more information on levels of curation and how these were applied in practice at two institutions, please see \u201cConceptualizing Data Curation Activities Within Two Academic Libraries\u201d ( Lafferty-Hess et al. 2020 ) Level Description Level 1 The minimum steps required to successfully publish in Dataverse and make the dataset findable, i.e., the dataset has been submitted to the proper dataverse and required metadata fields are accurate. Level 2 Activities that enhance the discoverability of datasets and help ensure their usability over time. E.g., recommended metadata fields are populated and dataset includes sufficient documentation to allow a user with a similar background to understand the dataset and open and use the files. Level 3 Intensive curation actions intended to prepare datasets for preservation and improve the chances that data and code can be used to reproduce or replicate an associated study. For example, supporting documentation is enhanced, the content of files and code are reviewed, and data files are transformed into formats suitable for long-term preservation. Complementary Guides Dataverse North Metadata Best Practices Guide This guide provides direction to both the novice and experienced users in creating metadata for datasets in Dataverse. It provides definitions for each field in Dataverse and tips for clarification where needed and distinguishes between requites, recommended, and optional fields. Scholars Portal Dataverse Guide This guide provides an overview of the steps to depositing a dataset in Scholars Portal Dataverse, the largest Dataverse instance in Canada. For advanced guidance, see the Harvard Dataverse Project User Guide. Data Curation Network (DCN) Curation Workflow The DCN developed this standardized set of C-U-R-A-T-E-D steps and checklists which has been adapted for this C-U-R-A-T-I-O-N framework. Quick Guide CURATION Steps Exemplar Datasets Curation Resources","title":"Home"},{"location":"#dataverse-curation-guide","text":"","title":"Dataverse Curation Guide"},{"location":"#introduction","text":"Data curation \u2013 the active management of research data as it is created, maintained, used, archived, shared, and reused \u2013 is a core component within the assemblage of infrastructure, processes, schemas, and curator expertise that supports best practices in Research Data Management (RDM). The execution of a well-articulated data curation workflow can make good data better by expertly describing its contents, creating a coherent structure, providing meaningful documentation, enabling automation through code and syntax, and linking to other data and outputs. This guide provides step-by-step instructions for curating new datasets deposited in Dataverse. The guide is framed around the acronym CURATION to provide an easy reminder for curators, especially those starting out, of the main steps in the curation process. This framework is adapted from the Data Curation Network\u2019s CURATED steps ( Johnston et al. 2018 ) for use in a bilingual context and is intended to outline and provide guidance on curation best practices in Dataverse. Data curation is not always a linear process; the type of data you are working with, your institutional policies or practices, your comfort level with curation, and the amount of time the researcher is able to dedicate to the process may require you to skip steps or complete the steps in a different order. You may also need to circle back and complete some of the steps a second time. The level of curation your institution is able to offer, given competing priorities and number of staff dedicated to the curation service, may also determine how many curation steps you can complete. Our Guide acknowledges there is no \u201cone size fits all\u201d model to data curation. The level and quality of curation is dependent on local resourcing, capacity, policies, priorities, and institutional strategic direction. As a result, the Guide has been developed with flexibility in mind. It can be used by new or experienced curators within academic institutions of all sizes, and it can be adapted by institutions to meet the needs of local policies and procedures.","title":"Introduction"},{"location":"#possible-curation-service-scenarios","text":"Service Type Description Unmediated Curation There is no intervention from the RDM service. The researcher creates their own dataverse and dataset, submits their data and publishes it. Semi-mediated curation The RDM service creates a dataverse or starts a dataset deposit and assigns a role to the researcher. The researcher submits data to their dataverse (or dataset). Depending on local policy, the dataset is either flagged for review by the institutional dataverse administrators, or the depositor requests to have the dataset reviewed by the data management team before or after it is published. Mediated curation Data is submitted by the researcher to the RDM service. The RDM service creates the dataverse (or dataset) and the data is curated by the library and published once approved by the researcher.","title":"Possible Curation Service Scenarios"},{"location":"#levels-of-curation","text":"The CURATION checklist is divided into 3 levels: Level 1, Level 2 and Level 3. Level 1 is the basic required information that should be completed to publish a dataset in Dataverse. Depending on the level of service that your institution is able to provide, you may be able to complete some of the items in levels 2 and 3. A description of each level is below. For more information on levels of curation and how these were applied in practice at two institutions, please see \u201cConceptualizing Data Curation Activities Within Two Academic Libraries\u201d ( Lafferty-Hess et al. 2020 ) Level Description Level 1 The minimum steps required to successfully publish in Dataverse and make the dataset findable, i.e., the dataset has been submitted to the proper dataverse and required metadata fields are accurate. Level 2 Activities that enhance the discoverability of datasets and help ensure their usability over time. E.g., recommended metadata fields are populated and dataset includes sufficient documentation to allow a user with a similar background to understand the dataset and open and use the files. Level 3 Intensive curation actions intended to prepare datasets for preservation and improve the chances that data and code can be used to reproduce or replicate an associated study. For example, supporting documentation is enhanced, the content of files and code are reviewed, and data files are transformed into formats suitable for long-term preservation.","title":"Levels of Curation"},{"location":"#complementary-guides","text":"Dataverse North Metadata Best Practices Guide This guide provides direction to both the novice and experienced users in creating metadata for datasets in Dataverse. It provides definitions for each field in Dataverse and tips for clarification where needed and distinguishes between requites, recommended, and optional fields. Scholars Portal Dataverse Guide This guide provides an overview of the steps to depositing a dataset in Scholars Portal Dataverse, the largest Dataverse instance in Canada. For advanced guidance, see the Harvard Dataverse Project User Guide. Data Curation Network (DCN) Curation Workflow The DCN developed this standardized set of C-U-R-A-T-E-D steps and checklists which has been adapted for this C-U-R-A-T-I-O-N framework.","title":"Complementary Guides"},{"location":"#quick-guide","text":"","title":"Quick Guide"},{"location":"#curation-steps","text":"","title":"CURATION Steps"},{"location":"#exemplar-datasets","text":"","title":"Exemplar Datasets"},{"location":"#curation-resources","text":"","title":"Curation Resources"},{"location":"curation/","text":"CURATION Steps Step Description C Check U Understand R Recommend A Augment T Transform I Include O Optimize N Note Down Check Understand In the Understand step, you should ensure the dataset is well-described and that end users will have a clear picture of what the data is and how it can be used. Review the metadata and documentation for thoroughness and clarity, create or recommend additional documentation if required, and check for usability issues such as missing data, code execution failures, ambiguous headings, and data presentation concerns. You may also screen for disclosure risk, intellectual property rights infringements, and other tasks, dependent on your institution\u2019s policies and the level of curation service your repository provides. For a thorough overview of steps you might take to understand the data and assess its completeness and usability, see Johnston (2017, Step 3.0). The Data Curation Network\u2019s Data Curation Primers (2019) are another excellent resource with guidance and best practice advice for curating specific file types. They include information about tools for file review and specify information that will be necessary to ensure the usability of the data over time. Level 2 Supporting documentation is thorough, accurate, and complete If the dataset has a Readme file, codebook, user manuals or other documentation, review it for accuracy and completeness. The documentation should provide contextual information about the dataset to increase its usability. If documentation is inadequate, work with the researcher to enhance existing documentation, or provide them with templates and other guidance to create documentation. Cornell University\u2019s \u201cGuide to writing \u201creadme\u201d style metadata\u201d (n.d.) and University of British Columbia\u2019s \u201cCreating a README for your Dataset: Quick Guide\u201d (Brigham 2020) are useful resources for both curators and researchers. Yes No Some Issue N/A Documentation includes a list of files... \u2610 \u2610 \u2610 \u2610 Contextual information about the data (how the data was collected or generated, the goal of the research). \u2610 \u2610 \u2610 \u2610 Description of file naming conventions and the structure of the files, if important. \u2610 \u2610 \u2610 \u2610 Record of how the data were modified or processed. \u2610 \u2610 \u2610 \u2610 Information about confidentiality and any restrictions placed on secondary use. \u2610 \u2610 \u2610 \u2610 Names of labels and variables, information about allowable values and units of measure, codes and classifications, if applicable. \u2610 \u2610 \u2610 \u2610 Explanations of codes and classifications. \u2610 \u2610 \u2610 \u2610 Description of the computing environment required to run any code that has been included (operating system, software packages and dependencies). Files open properly and contents appear as expected Download the dataset and extract the contents of any archive file types (.zip, .tar, etc.). Review file content and address any issues with proprietary files. Tip: For unfamiliar file types, does the documentation provide guidance on what software was used to generate the file, or how it might be viewed? Try opening the file in a text editor as even binary files may have plain text headers with information about the instrument or software that generated the file. If it is not feasible to open all files, check a subset that contains: At least one of every file type in the submitted dataset, Script files, code, and anything you suspect may be licensed, Any file you have reason to believe may include sensitive information. Yes No Some Issue N/A . \u2610 \u2610 \u2610 \u2610 Files open as expected and archive file formats extract without issue (unknown software, incompatible versions, or no access to the software could be a reason for files not running). \u2610 \u2610 \u2610 \u2610 If the files are not accessible, has the researcher provided a non-proprietary version of the files? \u2610 \u2610 \u2610 \u2610 If non-proprietary files cannot be provided, does the Readme describe how the data were generated, and the software necessary to use the data? \u2610 \u2610 \u2610 \u2610 File contents are consistent with expected structure and encoding. \u2610 \u2610 \u2610 \u2610 Readme file describes the data files and includes the following: \u2610 Summary description \u2610 File formats (flagged if proprietary) \u2610 File size \u2610 Path and/or tree structure \u2610 Hash (MD5) Files and folders are named and structured appropriately Ideally, files should be named and organized in a manner that is understandable and allows end users to easily navigate the contents of the dataset. The directory structure should be simple and directory names should clearly communicate their contents. The criteria below, provided by the University of Victoria (Khair 2020), are general best practices, and conventions for specific data types or discipline may differ. Yes No Some Issue N/A . \u2610 \u2610 \u2610 \u2610 Filenames are free of spaces or special characters and use underscores or hyphens as delimiters (e.g., Datacollection_20201009_v02.csv). \u2610 \u2610 \u2610 \u2610 File and directory names are concise, consistent, and understandable. \u2610 \u2610 \u2610 \u2610 Dates in filenames use consistent formatting (e.g., YYYYMMDD). \u2610 \u2610 \u2610 \u2610 Filenames use leading zeros for version numbers (e.g., v_012). \u2610 \u2610 \u2610 \u2610 Files are grouped in a logical folder structure and are not overly nested. Note: Folder structure may be dependent on the code, syntax, or output of a piece of software. Level 3 Code is well commented and produces the expected results The researcher may have included script files that were used to process or analyze the data, code that extends an existing model, executable files, or other software. While it may be beneficial to keep script files with the data, there are many purpose-built repository options for code and software that have robust version control systems and allow for ongoing development. You may suggest an alternate solution for publishing and archiving software and/or review the code and associated documentation alongside the data deposit. Yes No Some Issue N/A If the dataset includes software or code... \u2610 \u2610 \u2610 \u2610 Is the code also available in GitLab, GitHub, Bitbucket, or another purpose-built repository? - If yes, consider asking the researcher to archive it in the Software Heritage archive and link to it from the dataset metadata record. - If no, and the researcher has included more than data processing or analysis scripts (such as .r, .m, or .do files), consider suggesting a purpose-built repository. \u2610 \u2610 \u2610 \u2610 Is the code (or part of the code) derived from another source? \u2610 \u2610 \u2610 \u2610 If the code is derived from another source, does the original source code allow for redistribution? Is the license compatible with the license of the original source? \u2610 \u2610 \u2610 \u2610 If an executable file is included, is the source code also available? \u2610 \u2610 \u2610 \u2610 Code is well commented \u2610 The code contains header information such as: author, version number, filename, license \u2610 The function or purpose of the code is clear (from the Readme and/or embedded description) \u2610 If applicable, the depositor included information about how to run the code \u2610 The required software packages and dependencies are listed \u2610 Comments are concise and clear and describe the intention of the line(s) of code that follow, and/or the code itself is expressive (can be understood by humans and machines) \u2610 \u2610 \u2610 \u2610 The Readme or a header in the code itself includes information about: \u2610 The license \u2610 The developer\u2019s name and contact information \u2610 The version, and the date the code was last modified and/or run \u2610 Any sources the code (or part of the code) was derived from \u2610 Instructions on how to install or use the code. If there are multiple scripts, the order in which they are run should be clear \u2610 Required software packages and dependencies \u2610 Information about the environment in which the code was developed and/or can be used \u2610 Information about required input and expected output Submission contains potential sensitivities Note: Most instances of Dataverse allow researchers to restrict access to datasets, either temporarily or in perpetuity; however, Dataverse is not an enclave suitable for sensitive data. Review your Dataverse policies and/or consult with your administrator to confirm what types of information are suitable for your Dataverse ... NEED TO COMPLETE THIS SECTION Yes No Some Issue N/A . \u2610 \u2610 \u2610 \u2610 \u2610 \u2610 \u2610 \u2610 \u2610 \u2610 \u2610 \u2610 \u2610 \u2610 \u2610 \u2610 \u2610 \u2610 \u2610 \u2610 Submission contains data or code from third party sources Datasets should be inspected for data or code from third-party sources to verify that researchers have the proper rights or permissions to share data, and that proper attribution has been provided. Although resources may be free to access, view, or use it does not necessarily follow that they are free to redistribute. Consult with your copyright office or specialists on your campus to determine how your organization\u2019s policies regarding third-party intellectual property and rights affect deposit into your repositories. Yes No Some Issue N/A . \u2610 \u2610 \u2610 \u2610 Dataset contains proprietary or restricted information. Example: commercially licensed or proprietary data or code, or third-party data that are only accessible by registering or logging in. \u2610 \u2610 \u2610 \u2610 Third-party data or code has been properly cited and the original terms of use allow for redistribution. \u2610 \u2610 \u2610 \u2610 A data sharing agreement is referenced or included and allows for information to be redistributed. Recommend Augment Transform Include Optimize Note Down","title":"CURATION Steps"},{"location":"curation/#curation-steps","text":"Step Description C Check U Understand R Recommend A Augment T Transform I Include O Optimize N Note Down","title":"CURATION Steps"},{"location":"curation/#check","text":"","title":"Check"},{"location":"curation/#understand","text":"In the Understand step, you should ensure the dataset is well-described and that end users will have a clear picture of what the data is and how it can be used. Review the metadata and documentation for thoroughness and clarity, create or recommend additional documentation if required, and check for usability issues such as missing data, code execution failures, ambiguous headings, and data presentation concerns. You may also screen for disclosure risk, intellectual property rights infringements, and other tasks, dependent on your institution\u2019s policies and the level of curation service your repository provides. For a thorough overview of steps you might take to understand the data and assess its completeness and usability, see Johnston (2017, Step 3.0). The Data Curation Network\u2019s Data Curation Primers (2019) are another excellent resource with guidance and best practice advice for curating specific file types. They include information about tools for file review and specify information that will be necessary to ensure the usability of the data over time.","title":"Understand"},{"location":"curation/#level-2","text":"","title":"Level 2"},{"location":"curation/#supporting-documentation-is-thorough-accurate-and-complete","text":"If the dataset has a Readme file, codebook, user manuals or other documentation, review it for accuracy and completeness. The documentation should provide contextual information about the dataset to increase its usability. If documentation is inadequate, work with the researcher to enhance existing documentation, or provide them with templates and other guidance to create documentation. Cornell University\u2019s \u201cGuide to writing \u201creadme\u201d style metadata\u201d (n.d.) and University of British Columbia\u2019s \u201cCreating a README for your Dataset: Quick Guide\u201d (Brigham 2020) are useful resources for both curators and researchers. Yes No Some Issue N/A Documentation includes a list of files... \u2610 \u2610 \u2610 \u2610 Contextual information about the data (how the data was collected or generated, the goal of the research). \u2610 \u2610 \u2610 \u2610 Description of file naming conventions and the structure of the files, if important. \u2610 \u2610 \u2610 \u2610 Record of how the data were modified or processed. \u2610 \u2610 \u2610 \u2610 Information about confidentiality and any restrictions placed on secondary use. \u2610 \u2610 \u2610 \u2610 Names of labels and variables, information about allowable values and units of measure, codes and classifications, if applicable. \u2610 \u2610 \u2610 \u2610 Explanations of codes and classifications. \u2610 \u2610 \u2610 \u2610 Description of the computing environment required to run any code that has been included (operating system, software packages and dependencies).","title":"Supporting documentation is thorough, accurate, and complete"},{"location":"curation/#files-open-properly-and-contents-appear-as-expected","text":"Download the dataset and extract the contents of any archive file types (.zip, .tar, etc.). Review file content and address any issues with proprietary files. Tip: For unfamiliar file types, does the documentation provide guidance on what software was used to generate the file, or how it might be viewed? Try opening the file in a text editor as even binary files may have plain text headers with information about the instrument or software that generated the file. If it is not feasible to open all files, check a subset that contains: At least one of every file type in the submitted dataset, Script files, code, and anything you suspect may be licensed, Any file you have reason to believe may include sensitive information. Yes No Some Issue N/A . \u2610 \u2610 \u2610 \u2610 Files open as expected and archive file formats extract without issue (unknown software, incompatible versions, or no access to the software could be a reason for files not running). \u2610 \u2610 \u2610 \u2610 If the files are not accessible, has the researcher provided a non-proprietary version of the files? \u2610 \u2610 \u2610 \u2610 If non-proprietary files cannot be provided, does the Readme describe how the data were generated, and the software necessary to use the data? \u2610 \u2610 \u2610 \u2610 File contents are consistent with expected structure and encoding. \u2610 \u2610 \u2610 \u2610 Readme file describes the data files and includes the following: \u2610 Summary description \u2610 File formats (flagged if proprietary) \u2610 File size \u2610 Path and/or tree structure \u2610 Hash (MD5)","title":"Files open properly and contents appear as expected"},{"location":"curation/#files-and-folders-are-named-and-structured-appropriately","text":"Ideally, files should be named and organized in a manner that is understandable and allows end users to easily navigate the contents of the dataset. The directory structure should be simple and directory names should clearly communicate their contents. The criteria below, provided by the University of Victoria (Khair 2020), are general best practices, and conventions for specific data types or discipline may differ. Yes No Some Issue N/A . \u2610 \u2610 \u2610 \u2610 Filenames are free of spaces or special characters and use underscores or hyphens as delimiters (e.g., Datacollection_20201009_v02.csv). \u2610 \u2610 \u2610 \u2610 File and directory names are concise, consistent, and understandable. \u2610 \u2610 \u2610 \u2610 Dates in filenames use consistent formatting (e.g., YYYYMMDD). \u2610 \u2610 \u2610 \u2610 Filenames use leading zeros for version numbers (e.g., v_012). \u2610 \u2610 \u2610 \u2610 Files are grouped in a logical folder structure and are not overly nested. Note: Folder structure may be dependent on the code, syntax, or output of a piece of software.","title":"Files and folders are named and structured appropriately"},{"location":"curation/#level-3","text":"","title":"Level 3"},{"location":"curation/#code-is-well-commented-and-produces-the-expected-results","text":"The researcher may have included script files that were used to process or analyze the data, code that extends an existing model, executable files, or other software. While it may be beneficial to keep script files with the data, there are many purpose-built repository options for code and software that have robust version control systems and allow for ongoing development. You may suggest an alternate solution for publishing and archiving software and/or review the code and associated documentation alongside the data deposit. Yes No Some Issue N/A If the dataset includes software or code... \u2610 \u2610 \u2610 \u2610 Is the code also available in GitLab, GitHub, Bitbucket, or another purpose-built repository? - If yes, consider asking the researcher to archive it in the Software Heritage archive and link to it from the dataset metadata record. - If no, and the researcher has included more than data processing or analysis scripts (such as .r, .m, or .do files), consider suggesting a purpose-built repository. \u2610 \u2610 \u2610 \u2610 Is the code (or part of the code) derived from another source? \u2610 \u2610 \u2610 \u2610 If the code is derived from another source, does the original source code allow for redistribution? Is the license compatible with the license of the original source? \u2610 \u2610 \u2610 \u2610 If an executable file is included, is the source code also available? \u2610 \u2610 \u2610 \u2610 Code is well commented \u2610 The code contains header information such as: author, version number, filename, license \u2610 The function or purpose of the code is clear (from the Readme and/or embedded description) \u2610 If applicable, the depositor included information about how to run the code \u2610 The required software packages and dependencies are listed \u2610 Comments are concise and clear and describe the intention of the line(s) of code that follow, and/or the code itself is expressive (can be understood by humans and machines) \u2610 \u2610 \u2610 \u2610 The Readme or a header in the code itself includes information about: \u2610 The license \u2610 The developer\u2019s name and contact information \u2610 The version, and the date the code was last modified and/or run \u2610 Any sources the code (or part of the code) was derived from \u2610 Instructions on how to install or use the code. If there are multiple scripts, the order in which they are run should be clear \u2610 Required software packages and dependencies \u2610 Information about the environment in which the code was developed and/or can be used \u2610 Information about required input and expected output","title":"Code is well commented and produces the expected results"},{"location":"curation/#submission-contains-potential-sensitivities","text":"Note: Most instances of Dataverse allow researchers to restrict access to datasets, either temporarily or in perpetuity; however, Dataverse is not an enclave suitable for sensitive data. Review your Dataverse policies and/or consult with your administrator to confirm what types of information are suitable for your Dataverse ... NEED TO COMPLETE THIS SECTION Yes No Some Issue N/A . \u2610 \u2610 \u2610 \u2610 \u2610 \u2610 \u2610 \u2610 \u2610 \u2610 \u2610 \u2610 \u2610 \u2610 \u2610 \u2610 \u2610 \u2610 \u2610 \u2610","title":"Submission contains potential sensitivities"},{"location":"curation/#submission-contains-data-or-code-from-third-party-sources","text":"Datasets should be inspected for data or code from third-party sources to verify that researchers have the proper rights or permissions to share data, and that proper attribution has been provided. Although resources may be free to access, view, or use it does not necessarily follow that they are free to redistribute. Consult with your copyright office or specialists on your campus to determine how your organization\u2019s policies regarding third-party intellectual property and rights affect deposit into your repositories. Yes No Some Issue N/A . \u2610 \u2610 \u2610 \u2610 Dataset contains proprietary or restricted information. Example: commercially licensed or proprietary data or code, or third-party data that are only accessible by registering or logging in. \u2610 \u2610 \u2610 \u2610 Third-party data or code has been properly cited and the original terms of use allow for redistribution. \u2610 \u2610 \u2610 \u2610 A data sharing agreement is referenced or included and allows for information to be redistributed.","title":"Submission contains data or code from third party sources"},{"location":"curation/#recommend","text":"","title":"Recommend"},{"location":"curation/#augment","text":"","title":"Augment"},{"location":"curation/#transform","text":"","title":"Transform"},{"location":"curation/#include","text":"","title":"Include"},{"location":"curation/#optimize","text":"","title":"Optimize"},{"location":"curation/#note-down","text":"","title":"Note Down"},{"location":"datasets/","text":"Exemplar Datasets","title":"Exemplar Datasets"},{"location":"datasets/#exemplar-datasets","text":"","title":"Exemplar Datasets"},{"location":"quick/","text":"Quick Guide Dataverse CURATION Quick Reference Guide Level 1: The minimum steps required to successfully publish in Dataverse and make the dataset findable, i.e., the dataset has been submitted to the proper dataverse and required metadata fields are accurate. Level 2: Activities that enhance the discoverability of datasets and help ensure their usability over time. E.g., recommended metadata fields are populated and dataset includes sufficient documentation to allow a user with a similar background to understand the dataset and open and use the files. Level 3: Intensive curation actions intended to prepare datasets for preservation and improve the chances that data and code can be used to reproduce or replicate an associated study. For example, supporting documentation is enhanced, the content of files and code are reviewed, and data files are transformed into formats suitable for long-term preservation. Step Definition Major Tasks Level 1 Level 2 Level 3 C Check Ensure that all the data and metadata components required to successfully publish the dataset are present and in working order \u2610 Dataset has been submitted to the proper dataverse X ^ ^ \u2610 All files described in the documentation are included in the dataset X","title":"Quick Guide"},{"location":"quick/#quick-guide","text":"","title":"Quick Guide"},{"location":"quick/#dataverse-curation-quick-reference-guide","text":"Level 1: The minimum steps required to successfully publish in Dataverse and make the dataset findable, i.e., the dataset has been submitted to the proper dataverse and required metadata fields are accurate. Level 2: Activities that enhance the discoverability of datasets and help ensure their usability over time. E.g., recommended metadata fields are populated and dataset includes sufficient documentation to allow a user with a similar background to understand the dataset and open and use the files. Level 3: Intensive curation actions intended to prepare datasets for preservation and improve the chances that data and code can be used to reproduce or replicate an associated study. For example, supporting documentation is enhanced, the content of files and code are reviewed, and data files are transformed into formats suitable for long-term preservation. Step Definition Major Tasks Level 1 Level 2 Level 3 C Check Ensure that all the data and metadata components required to successfully publish the dataset are present and in working order \u2610 Dataset has been submitted to the proper dataverse X ^ ^ \u2610 All files described in the documentation are included in the dataset X","title":"Dataverse CURATION Quick Reference Guide"},{"location":"resources/","text":"Resources","title":"Resources"},{"location":"resources/#resources","text":"","title":"Resources"}]}